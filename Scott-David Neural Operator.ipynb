{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 0.0025 100 0.5\n",
      "torch.Size([1000, 64, 64, 2])\n",
      "torch.Size([200, 64, 64, 2])\n",
      "preprocessing finished, time used: 17.848776034006733\n",
      "926517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-49263348932d>:61: UserWarning: The function torch.rfft is deprecated and will be removed in a future PyTorch release. Use the new torch.fft module functions, instead, by importing torch.fft and calling torch.fft.fft or torch.fft.rfft. (Triggered internally at  /opt/conda/conda-bld/pytorch_1607370117127/work/aten/src/ATen/native/SpectralOps.cpp:590.)\n",
      "  x_ft = torch.rfft(x, 2, normalized=True, onesided=True)\n",
      "<ipython-input-1-49263348932d>:71: UserWarning: The function torch.irfft is deprecated and will be removed in a future PyTorch release. Use the new torch.fft module functions, instead, by importing torch.fft and calling torch.fft.ifft or torch.fft.irfft. (Triggered internally at  /opt/conda/conda-bld/pytorch_1607370117127/work/aten/src/ATen/native/SpectralOps.cpp:602.)\n",
      "  x = torch.irfft(out_ft, 2, normalized=True, onesided=True, signal_sizes=(x.size(-2), x.size(-1)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 40.30181629200524 0.15195404033362866 0.1534847814925015 0.18532634247094393 0.1879283130913973\n",
      "1 37.768681269997614 0.09257938171736896 0.093930448429659 0.19621368784457446 0.20083853511139751\n",
      "2 38.340476108001894 0.07909611418657005 0.08035548323951662 0.15545687023550273 0.15818860834464432\n",
      "3 38.53105846600374 0.07394480232708156 0.07532105411402881 0.12190016409382225 0.12285329280421138\n",
      "4 38.922719450012664 0.0679126758929342 0.06916237312741577 0.11893218696117401 0.12081456452608108\n",
      "5 40.1269338009879 0.06773151951655745 0.0690442645996809 0.15337530113756656 0.15517105186358093\n",
      "6 38.07031911899685 0.062467125833034515 0.06372603782825172 0.13082848897203803 0.13192732591181994\n",
      "7 38.1772986970027 0.05980601353012025 0.06099431964661926 0.13600995594635606 0.13735650323331355\n",
      "8 38.627788452999084 0.057235793277621266 0.05837741803005338 0.1002057046815753 0.10187120993621647\n",
      "9 37.83480367201264 0.05776745788380504 0.05899507644213736 0.1046176533959806 0.1063590706139803\n",
      "10 35.16486807099136 0.05390910187363625 0.0550475367475301 0.11297173717990518 0.11482241444289684\n",
      "11 35.58678147100727 0.05578618799522519 0.05694311240967363 0.11180438816547394 0.11314784763380885\n",
      "12 40.01821355499851 0.052917588029056786 0.05405900597944856 0.11099061872810126 0.11317542091012\n",
      "13 35.655971501008025 0.05174408322107047 0.052921242269687356 0.10187921846285462 0.10388320852071047\n",
      "14 39.511351940993336 0.04976363276783377 0.05089171510282904 0.11612780509516597 0.11824880940839648\n",
      "15 37.72586088300159 0.05003165785036981 0.05114379646722227 0.10416830321773887 0.10606025017797947\n",
      "16 37.811078526006895 0.050256475917994974 0.051386482276953756 0.09425079699605704 0.09666604161262513\n",
      "17 37.893438808998326 0.04858086850773543 0.04963858227711171 0.09425110019743442 0.09711582394316792\n",
      "18 38.586446257992066 0.047773624286986886 0.04888077675830573 0.10074362505227327 0.10233423681929707\n",
      "19 37.82377281699155 0.047588364988565446 0.0486225426197052 0.08796108359470964 0.09050901127979159\n",
      "20 38.06965987100557 0.04657602248433977 0.047645569935441015 0.0874072272144258 0.0903262547403574\n",
      "21 38.7949698260054 0.044408953187055886 0.045383830593898895 0.0832355409488082 0.08568689661100506\n",
      "22 38.372229779997724 0.044023190733045336 0.045114902529865504 0.08098866079002619 0.08379559220746159\n",
      "23 39.0880369279912 0.044308487145230176 0.045301551008597014 0.08155376922339201 0.08384073682129384\n",
      "24 38.26072060500155 0.04360163344815374 0.04466130878031254 0.08730714466422797 0.08961996724829077\n",
      "25 37.48497658599808 0.043096524124033746 0.04418251645565033 0.08413448614068329 0.08723442801274359\n",
      "26 37.500540495995665 0.04135011009685695 0.042304139429703354 0.07981407821178436 0.08283284448087215\n",
      "27 37.50191211300262 0.041853620247915384 0.04288818013574928 0.08364926535636187 0.08681646402925253\n",
      "28 36.70673199099838 0.042853896872140466 0.04387357399147004 0.08035672990605235 0.08312395995482802\n",
      "29 35.33281541700126 0.041066408052109184 0.042059181447140874 0.08189656114205718 0.08528752371668816\n",
      "30 37.65866147800989 0.041693238447420296 0.04270443772338331 0.08001125682145357 0.08335588542744517\n",
      "31 37.56483293299971 0.03896569801028818 0.03994453006051481 0.07954731348901987 0.08317805473692715\n",
      "32 37.58480237099866 0.0421927413130179 0.04320341277029365 0.07618240216746926 0.07926111652515828\n",
      "33 33.62495866899553 0.03906257164943963 0.040041507279500364 0.08220279119908809 0.08564747354015707\n",
      "34 37.5760550640116 0.03999788149446249 0.040926783291623 0.08232134534977377 0.08528223142027855\n",
      "35 37.48896885600698 0.040367458443157374 0.04131742024049163 0.0819768800213933 0.08511001856997609\n",
      "36 37.583953277993714 0.03890609450731426 0.039873572862707075 0.07646120036020874 0.07990782182663679\n",
      "37 37.43687879999925 0.03962146633584052 0.04062154123652727 0.07792666150256991 0.08104823675006628\n",
      "38 37.35857593100809 0.03862477645091712 0.03960490750987083 0.07495326159521937 0.07828035427257418\n",
      "39 37.58200890599983 0.03797513983771205 0.03895139381289482 0.08088856535963714 0.08347415398806333\n",
      "40 37.678653540002415 0.0376901705507189 0.03862901616562158 0.07596421057358384 0.07927686985582114\n",
      "41 38.036888136994094 0.036795784247107804 0.0377740450296551 0.07687779891304672 0.08042970118112862\n",
      "42 37.70041568999295 0.03727937362436205 0.038211610096506775 0.0768429308012128 0.07980787734501064\n",
      "43 37.99812812599703 0.03624989087879658 0.03717025186773389 0.07253426881507039 0.07609247046522796\n",
      "44 38.283605931006605 0.037927607004530725 0.03891123016551137 0.07234413984231651 0.07565502335317432\n",
      "45 38.38149530200462 0.03749878989718854 0.03844473784789443 0.07385873418301343 0.0772127443458885\n",
      "46 37.824795205000555 0.03696607551537454 0.0379610231872648 0.0747202630713582 0.07801125612109899\n",
      "47 37.82197090200498 0.03720518510602415 0.03815267357695848 0.07500362536869944 0.07833316808566451\n",
      "48 38.20813737799472 0.03640186816360801 0.037368979218415914 0.07062628685496747 0.07436619984917342\n",
      "49 37.830880722991424 0.036985745233483615 0.03791896916273981 0.07656524002552033 0.08030461015179753\n",
      "50 37.80722900299588 0.03490132449008525 0.03583653669152409 0.07290796043351293 0.076002550534904\n",
      "51 37.723164399998495 0.036664082779549065 0.037627728786319495 0.0769314737059176 0.08047887572087348\n",
      "52 38.04473408100603 0.03613501611258835 0.0370977198947221 0.07313137171790003 0.07676247064955533\n",
      "53 38.15528839098988 0.03577374385669827 0.03671442621666938 0.07651721384376288 0.0802212374098599\n",
      "54 38.25466792100633 0.0358030974091962 0.036702548442408445 0.07692809186875821 0.07969796996563673\n",
      "55 37.90491880101035 0.03465971339121461 0.0356060886234045 0.07223604141734541 0.07571634805761278\n",
      "56 38.06321621600364 0.03405841604061425 0.035015550666488704 0.06802508733235299 0.07119974753819407\n",
      "57 37.728081383000244 0.034939862323924896 0.035841916104778646 0.07425662538968027 0.07776069515384734\n",
      "58 37.77402494600392 0.03475698713026941 0.03573933117091656 0.07548282235860825 0.07879069091752172\n",
      "59 37.9450227740017 0.03495149252284318 0.03589175534527749 0.06892372673377395 0.07204603889025747\n",
      "60 37.88624262200028 0.034894578761421144 0.03581200553663075 0.07415995077230036 0.07763609110377728\n",
      "61 37.96669898999971 0.03484797379747033 0.035780355881899595 0.07433068454265594 0.07767418021336198\n",
      "62 38.020627664998756 0.03508208491746336 0.036000523352995514 0.06910781119018793 0.07256150948815047\n",
      "63 36.66993239099975 0.032806101595982906 0.03371379313059151 0.07214954967610537 0.07539454341866075\n",
      "64 37.81569579200004 0.03606602805946022 0.03703197833243758 0.07153488207608462 0.07492263723164796\n",
      "65 38.045195693994174 0.034567826171405615 0.035513407920487225 0.0679529124032706 0.07163558047264815\n",
      "66 37.89338738899096 0.03317983521707356 0.03412151266913861 0.06665006898343563 0.07088460273109376\n",
      "67 37.819082945003174 0.03363988190330565 0.03452276879921556 0.06872363943606614 0.07210821524262429\n",
      "68 37.82686477199604 0.03435086830984801 0.03528456270974129 0.06937961656600238 0.07292533557862044\n",
      "69 37.74433349100582 0.033652513247914614 0.034539844914339486 0.07173889567144215 0.07515856972895563\n",
      "70 37.787131745004444 0.033548799770884215 0.03448846289236099 0.06629241217859089 0.0698004917986691\n",
      "71 37.911931937997 0.03480605664849281 0.03570037171524018 0.06986462502740323 0.07292745693586766\n",
      "72 37.704444774004514 0.0342978108022362 0.035199614746496084 0.07032867443747819 0.07349150491878391\n",
      "73 37.84627525000542 0.03382159103825688 0.034731261359527706 0.06967467771843076 0.07327529305592179\n",
      "74 37.82632754200313 0.03302169837243855 0.033923741380684075 0.0692356460634619 0.07272497024387121\n",
      "75 37.74129012800404 0.033022216307930646 0.03391006186977029 0.06845074381679296 0.07209788226522505\n",
      "76 37.652041843000916 0.03414862374588847 0.03504340083058923 0.07180178913287819 0.07573643958196044\n",
      "77 37.7943697800074 0.0339760145554319 0.034856118693947793 0.06554340886883438 0.0689628510735929\n",
      "78 37.12792289200297 0.03224639666313305 0.03309882716834545 0.0665316356252879 0.06984464049339295\n",
      "79 37.56671071899473 0.034039617746137084 0.03490718199498952 0.07080884345807135 0.07405951986089349\n",
      "80 37.74257305001083 0.033993870149366556 0.034943518364802 0.06942670568823814 0.07304309416562318\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81 37.77166063900222 0.0331540653295815 0.03400484789349139 0.06983676979318261 0.07347140084952115\n",
      "82 37.88113692600746 0.03320329341758042 0.034085401161573825 0.07031118498183787 0.07414906612597406\n",
      "83 37.94149020900659 0.03283234870899469 0.03372477998584509 0.06871005768887699 0.07257300942204893\n",
      "84 37.74588328199752 0.03298021431826055 0.033859852323774246 0.07390320308506489 0.07729255553334952\n",
      "85 34.08302597900911 0.03450994278583676 0.03538823889940977 0.06957835726439952 0.07334734609350563\n",
      "86 37.39043876499636 0.032474637245759365 0.03331810601521283 0.07105123563669621 0.07363605263642967\n",
      "87 37.75613068300299 0.033231713806279005 0.034076931741088626 0.07521517585963011 0.0784935836866498\n",
      "88 37.66727789500146 0.0325579370111227 0.03339468791987747 0.06448936807923018 0.06790241499431432\n",
      "89 37.96183521700732 0.032545828469097614 0.03342990148440003 0.06653055410832166 0.0697534792125225\n",
      "90 38.686560599002405 0.03186016974505037 0.03276857077330351 0.06438972802832722 0.06798605541698635\n",
      "91 37.92436781000288 0.032529617848806085 0.03339369733724743 0.06795354023575782 0.07101066131144762\n",
      "92 37.92624420199718 0.03264678043592721 0.03354286354687065 0.07100743572227657 0.07443720446899534\n",
      "93 37.76092750200769 0.032803779639303685 0.03364818989858031 0.06712566854432225 0.07045807154849172\n",
      "94 37.761036684009014 0.032484554393216965 0.033365209543146195 0.06728068807162345 0.07058779200538993\n",
      "95 37.56646524599637 0.031957273594103754 0.032799624407663944 0.0665058375801891 0.06992809060029685\n",
      "96 38.609905833000084 0.031979228254407646 0.03286542671173811 0.06225674659013748 0.0661879719980061\n",
      "97 41.5071151190059 0.03197608805261552 0.03286179157439619 0.0650134436134249 0.06843762789852917\n",
      "98 42.72643527400214 0.03192406292352826 0.03279547199513763 0.06469631558284164 0.0682453880738467\n",
      "99 41.12599977699574 0.033065455203875896 0.033920332830399275 0.06508347154594958 0.06831972423009575\n",
      "100 38.52163082599873 0.023813968216069042 0.02442856060806662 0.06140646442770958 0.06487584432587028\n",
      "101 37.436622991008335 0.024284371104557067 0.024905790289863942 0.0615596035681665 0.06483735153451561\n",
      "102 39.0003435289982 0.023581389750819654 0.024205539064016193 0.059903430230915544 0.06317562809213996\n",
      "103 38.014946276991395 0.024005624937824904 0.0246182303968817 0.060626935912296176 0.06409756815060973\n",
      "104 39.71143509200192 0.022694782419130206 0.02329760433640331 0.06082426599226892 0.06456750964745879\n",
      "105 38.2276552060066 0.02323396916501224 0.023863423119299114 0.0582403461728245 0.06155252351425588\n",
      "106 38.49683838599594 0.023394705916754903 0.024019589797593652 0.06271748976781964 0.06590023845434188\n",
      "107 38.53117222200672 0.02289197149593383 0.023523286311887204 0.06003053775988519 0.06319000258110463\n",
      "108 38.99368908999895 0.022788796414621174 0.02339385125041008 0.060291899405419826 0.06378821461461484\n",
      "109 40.53389092099678 0.02298208945430815 0.023602823591791094 0.06311510303989053 0.06646801964379848\n",
      "110 39.889030584992724 0.022814510896336286 0.023398194711189715 0.058685288140550254 0.062067412501201034\n",
      "111 40.154545270008384 0.02319872868154198 0.023812476647086443 0.05813465213403106 0.06143435492180288\n",
      "112 39.74695997699746 0.02284981052810326 0.02345445295702666 0.059588587060570714 0.0629875107202679\n",
      "113 39.69345434999559 0.022783326748758555 0.023367035346571356 0.05920007862150669 0.06255292128771543\n",
      "114 38.34473075000278 0.022280575011391194 0.02287819766625762 0.05710251641459763 0.060346896005794404\n",
      "115 39.45439910500136 0.022460915591102092 0.023068810265976937 0.058906390396878124 0.06233720220625401\n",
      "116 38.114543862990104 0.022897795412689447 0.023504741734825075 0.05858009115792811 0.06188721095211804\n",
      "117 38.01187382599164 0.023108149401377887 0.023735034500714392 0.058028751546517016 0.06143039125949144\n",
      "118 38.405229153999244 0.023072999713476747 0.02366231180401519 0.06187388244085014 0.06524024408310652\n",
      "119 39.069035601001815 0.022387951099313796 0.022960878445766865 0.06002291310578585 0.06319314832799136\n",
      "120 38.45065899800102 0.02271957580978051 0.02334155794000253 0.057502177432179453 0.060819186130538584\n",
      "121 38.18759086698992 0.022627729046624155 0.023228336845524607 0.0575782182905823 0.06093636471778154\n",
      "122 35.30762961199798 0.022381775880698115 0.022984708124306055 0.056970899691805243 0.06033671007957309\n",
      "123 37.41532691799512 0.022993324681650846 0.02359757548710331 0.0584378946851939 0.06161808401346207\n",
      "124 37.95602519399836 0.022280454562511296 0.02285400518681854 0.05571578198112547 0.058974995547905563\n",
      "125 38.467464158995426 0.022142167760524897 0.02274476139806211 0.056296171583235265 0.0594826203584671\n",
      "126 37.97906414400495 0.02300755109358579 0.023638418989721684 0.05774375557899475 0.06133415394462645\n",
      "127 38.727441373994225 0.02229533249605447 0.02288411694113165 0.05562695566564799 0.05894498563371599\n",
      "128 37.94082744300249 0.022474939643405377 0.02310428831866011 0.05759269230533391 0.06105198519770056\n",
      "129 37.58974684900022 0.02248668638477102 0.02308339596539736 0.05519174196757376 0.058267573062330484\n",
      "130 37.704577648008126 0.022102146931458264 0.02267580943228677 0.05632124158553779 0.05968962831422687\n",
      "131 37.99541929400584 0.022637293347157538 0.0231997783286497 0.05766061853151769 0.06115445245988667\n",
      "132 37.663723653997295 0.022459835977293553 0.023116514686495067 0.05520369277335704 0.058413856998085975\n",
      "133 37.575752117001684 0.02208535038214177 0.022682011130731553 0.057737518027424814 0.06095490828156471\n",
      "134 37.64708209900709 0.021832012123893945 0.022430371025577187 0.05660548971965909 0.05975323303602636\n",
      "135 38.06961393900565 0.02154006403731182 0.02214647381193936 0.05406032655388117 0.05737262657377869\n",
      "136 38.8003663670097 0.022602454083971678 0.023202489560935645 0.056277336403727535 0.059416136629879476\n",
      "137 38.357190609996906 0.022254454049281776 0.022879834732506425 0.05720039753243327 0.06050862513482571\n",
      "138 38.803372260998 0.021781928048469127 0.0223545969161205 0.05764784893486649 0.060823604171164336\n",
      "139 37.69431422499474 0.023114370791241526 0.023708560311701148 0.05673404546454549 0.05963713511824608\n",
      "140 37.74793208199844 0.02231470861565322 0.022901587805710732 0.05499392178840935 0.057972510987892745\n",
      "141 37.43143806500302 0.021874694705475123 0.02248941061180085 0.05605067973956466 0.059075360838323834\n",
      "142 38.94200374200591 0.02211078443704173 0.02271591410925612 0.05560843912884593 0.05890900968573987\n",
      "143 38.27699649499846 0.02262313554342836 0.023235574104823173 0.05614668382331729 0.058894136315211655\n",
      "144 36.27259523700923 0.021309966133907437 0.021917998001910747 0.05807706370018423 0.06120689700823277\n",
      "145 34.825035727000795 0.021957789659500123 0.02256343264086172 0.056475437143817545 0.05962371016852558\n",
      "146 38.55121187599434 0.021531336163170635 0.02212913097254932 0.05452267439104617 0.05771158231422305\n",
      "147 38.51385188799759 0.022758347587194295 0.023363021960947663 0.058968967921100554 0.06167695519048721\n",
      "148 37.75427881599171 0.022100252378731967 0.022711520763579757 0.05666563988663256 0.05984764953609556\n",
      "149 38.466960548001225 0.022376623595599086 0.022976933126803486 0.05459004228003323 0.057834093002602456\n",
      "150 38.8548229450098 0.021834479721728712 0.022414475063793363 0.05653531640768051 0.059830743209458886\n",
      "151 39.12869061600941 0.021809854038525374 0.022382299754302948 0.05577871473506093 0.05909072807058692\n",
      "152 37.476993630989455 0.021805997969117016 0.022379250932950526 0.058142491672188046 0.06051589865237474\n",
      "153 38.18905077900854 0.022175810185726733 0.02279072983376682 0.05577477861195803 0.059020253270864485\n",
      "154 40.69180607900489 0.02215485803456977 0.022758629732299595 0.0549269930832088 0.05806490451097488\n",
      "155 39.332324685994536 0.021689451328944415 0.022267669460270555 0.0539689324516803 0.05705619170330465\n",
      "156 39.973208267998416 0.021976279408670963 0.022570200683549046 0.05801871255040169 0.06115351636894047\n",
      "157 39.015804334005225 0.0215338503876701 0.02213220067275688 0.052190292198210954 0.05533238866366446\n",
      "158 39.55095090199029 0.02249076135456562 0.02313041207846254 0.05722200903110206 0.06040661374107003\n",
      "159 37.8027927820076 0.021945069299079478 0.022566594802774488 0.05623548574745655 0.059375538881868126\n",
      "160 37.49646725899947 0.021483797980472445 0.022079167368356137 0.053647537790238856 0.05657120220828801\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161 37.99483574599435 0.022297966711688787 0.02288541356381029 0.05541401349939406 0.058329702354967594\n",
      "162 38.17882819000806 0.0218577189729549 0.022441416333429515 0.05735689737368375 0.060323863229714336\n",
      "163 38.32262857499882 0.02225218509323895 0.02286179817095399 0.05770019092131406 0.06031518123112619\n",
      "164 38.6477690069878 0.021882315090391784 0.022493863785173745 0.054411659128963945 0.0575623282417655\n",
      "165 38.48711149599694 0.022017861200962215 0.022604506806470453 0.05632419831585139 0.05927390816621483\n",
      "166 38.570795442996314 0.022126265715807676 0.022734963460825385 0.05625644093379378 0.05917652796022594\n",
      "167 38.356090591987595 0.021807012697216122 0.02237436453672126 0.055644183033145965 0.05852049422450364\n",
      "168 39.7668663039949 0.02214305458171293 0.022726885804906487 0.054521206384524706 0.05741831302642822\n",
      "169 40.369370650005294 0.021608782428782433 0.02219988899677992 0.05599273135885596 0.05896750946063548\n",
      "170 38.95971862199076 0.021841272704303263 0.02242560574784875 0.05658120471984148 0.059745309902355076\n",
      "171 37.90393930200662 0.02150473083462566 0.022107423830311744 0.05416507768444717 0.05735768663696945\n",
      "172 38.5735129389941 0.021614476353861392 0.022202473023440687 0.05576054740231484 0.05873278064653278\n",
      "173 37.54390304700064 0.021719776899553834 0.022344986675307155 0.05477444260381162 0.05786926857195795\n",
      "174 37.43952683699899 0.02146197756100446 0.022071161252446472 0.055200369358062745 0.05807374966330826\n",
      "175 37.21975354599999 0.021361051096580923 0.02198104053037241 0.05448613334447146 0.05744494246318936\n",
      "176 37.826534651991096 0.022013117191381753 0.02263205836620182 0.057059685979038474 0.05968590429984033\n",
      "177 37.66933515900746 0.021510838519316167 0.022116626733914017 0.05468265675008297 0.05756507247686386\n",
      "178 37.82570716801274 0.021473758874461055 0.022056835017632694 0.056743673235178 0.05958072974346578\n",
      "179 36.80558154899336 0.022238168330863117 0.022842823514249176 0.053828075202181934 0.05673621189780533\n",
      "180 38.39801429200452 0.02180418804101646 0.02240805011289194 0.0557428275141865 0.0586310607008636\n",
      "181 37.17504636099329 0.022158972781617194 0.022766298514790832 0.055767120020464064 0.05885195980779827\n",
      "182 39.64956196800631 0.022227284421678633 0.022832605615258218 0.060391707196831707 0.06282179938629269\n",
      "183 39.781065410992596 0.021659498749766498 0.022235966409090906 0.05549183959141374 0.058339052237570285\n",
      "184 40.646186503989156 0.021257788595277816 0.02186068066721782 0.052794920029118654 0.05576624490320683\n",
      "185 39.448459585997625 0.0216210557105951 0.022213614041917025 0.05378056433983147 0.05674990980885923\n",
      "186 42.10325008399377 0.021833007780835034 0.02243396279402077 0.054739710432477294 0.05760170625522733\n",
      "187 40.56017908200738 0.021455394860357045 0.022041501946747304 0.056294488683342934 0.05887582175433636\n",
      "188 40.52031367200834 0.021643262676429003 0.02225102986721322 0.05449567081406712 0.05737343760207295\n",
      "189 40.188340622000396 0.021818348724860697 0.022405582868959755 0.05537427378818393 0.05819070124998689\n",
      "190 40.50638531400182 0.02233523004176095 0.022934810902457685 0.052583935777656736 0.055421031517907976\n",
      "191 39.467820423989906 0.02119063353026286 0.021779566276352854 0.05494742015376687 0.057951701674610376\n",
      "192 37.981512626996846 0.021778736342675985 0.02235293378215283 0.05552134607452899 0.058234957293607295\n",
      "193 37.92810133199964 0.02165727789653465 0.022253473873250187 0.05572791922837496 0.058579022204503416\n",
      "194 40.140552377997665 0.022020268484950065 0.02262902555754408 0.05285605937242508 0.05567961803637445\n",
      "195 37.9839662600134 0.021261589588597418 0.021866099625360222 0.05595345802605152 0.05873222545720637\n",
      "196 38.60027835400251 0.021576462784782053 0.022162225109525025 0.053483489453792575 0.05630032615736127\n",
      "197 39.349106809997465 0.02164432119624689 0.02227219673618674 0.05425014300271869 0.05717277825344354\n",
      "198 38.57169941600296 0.022067814477719366 0.02265730433119461 0.05644055978395045 0.05904519026167691\n",
      "199 38.60014057598892 0.022087305531837045 0.022692132643889636 0.06006613921374083 0.0625170772522688\n",
      "200 38.68575017100375 0.016762261278461664 0.017164111017715186 0.05224071876611561 0.05501248848158866\n",
      "201 39.34910521800339 0.016196562517434357 0.01658784955367446 0.05147804198320955 0.054105695034377274\n",
      "202 40.09298234200105 0.016673038105480372 0.01708609335590154 0.05273123459890485 0.05543750985059887\n",
      "203 38.99218492799264 0.016191767666954546 0.01659269630163908 0.05286924688145518 0.05555040403734893\n",
      "204 37.91224404600507 0.01601067991182208 0.016418351225554944 0.05401774053927511 0.05652140826452524\n",
      "205 38.49207372700039 0.01607801508717239 0.01648301546438597 0.05277017530519515 0.05551481908652931\n",
      "206 38.309366326997406 0.016040730298729614 0.01643605391564779 0.05146285431925207 0.054166923109441996\n",
      "207 38.35545474899118 0.016112059639766814 0.016501730524003506 0.05350527554750442 0.05604127854574472\n",
      "208 37.9013944069884 0.016130194515455516 0.016533495566109196 0.05322167438454926 0.05588588314596563\n",
      "209 38.10606235799787 0.015856865793000906 0.016267973772250116 0.053239384517073635 0.05570682770572603\n",
      "210 37.97495195499505 0.01598181175207719 0.01639018899644725 0.05074247759766877 0.053354827072471384\n",
      "211 37.81893110300007 0.0157966298549436 0.016188623667228966 0.050845191180706024 0.05345752970781177\n",
      "212 37.79282201699971 0.015756253302562983 0.01616523272637278 0.051793331000953916 0.05434157111216337\n",
      "213 38.94734216500365 0.01564447516715154 0.0160510356486775 0.05225176644511521 0.05488473344128579\n",
      "214 37.587941641002544 0.01578614239138551 0.01619268446881324 0.0504165095416829 0.053097406150773165\n",
      "215 37.52115803399647 0.015803204705938698 0.016226689185481518 0.049995078351348636 0.05242837932426483\n",
      "216 37.44056353099586 0.015906895950669422 0.01630122880707495 0.05137542710173875 0.05386408571153879\n",
      "217 37.54966855599196 0.016065822232048957 0.016471478382125496 0.05117894142866135 0.05380062635987997\n",
      "218 37.47286125298706 0.015860667625442148 0.016263214750448243 0.052516911402344706 0.05491009268444032\n",
      "219 37.80326234699169 0.016034476967994125 0.01643537626042962 0.05249108411371708 0.0548152572195977\n",
      "220 35.03600699499657 0.015715809892863034 0.01611676946748048 0.05358313804026693 0.056008572257123884\n",
      "221 36.537101221008925 0.015860019129468127 0.016273425014223904 0.05258660990744829 0.05499722401611507\n",
      "222 37.52964690299996 0.016117772805504502 0.016528213690035046 0.05335075931623578 0.05558448683004826\n",
      "223 37.58028439000191 0.015743895703228192 0.016129616572521627 0.050213535865768794 0.05266436360776425\n",
      "224 37.59956519200932 0.01563600479159504 0.016043101948220284 0.05187351816799492 0.05430198344402015\n",
      "225 37.632010180997895 0.01592401091940701 0.016335268417140468 0.04953319197986275 0.05199181294068694\n",
      "226 37.61398634999932 0.015800312181469052 0.016224438081495464 0.0489372961781919 0.05142252428922802\n",
      "227 37.81853327699355 0.01563517820579 0.01600957062863745 0.05075151308905333 0.05320002216845751\n",
      "228 37.45639427700371 0.01567252497933805 0.016065317414468153 0.05046190966852009 0.052899837796576324\n",
      "229 37.885538089001784 0.015500681919744238 0.015904932326171548 0.04960667893756181 0.05205592255108058\n",
      "230 38.103627039003186 0.015780320022720843 0.016190484332153574 0.05115897136274725 0.05359323647338897\n",
      "231 37.56483721100085 0.015776521706487984 0.016192637267522514 0.050357742672786115 0.052777453092858195\n",
      "232 37.841053687006934 0.015454174908343703 0.015853453209623693 0.050812059938907625 0.05328076637815684\n",
      "233 37.61310977699759 0.015867860108148307 0.016294674430973828 0.05006281853187829 0.0524781555403024\n",
      "234 37.59421327500604 0.015849840799113734 0.016259797452483325 0.05097724484279752 0.05332635201048106\n",
      "235 37.92634681100026 0.01595071004331112 0.01636609485652298 0.04978869820944965 0.052230617022141816\n",
      "236 38.15420463800547 0.01599954765662551 0.01640451955748722 0.04999047269579023 0.05233501705806702\n",
      "237 37.947809094999684 0.015604031621478498 0.01600729503505863 0.05100657528266311 0.05334645316936076\n",
      "238 37.67131855299522 0.015834654258098452 0.016251867123181 0.049228454339317974 0.05159851649776101\n",
      "239 37.44268374200328 0.015778248751536012 0.016166310876142235 0.05117810072377324 0.053335291724652054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240 37.56333586599794 0.015203140083700419 0.015614557089284062 0.04954386357218027 0.051877580471336844\n",
      "241 37.735169077001046 0.015475406141020357 0.015865154921542852 0.05052788988221437 0.052839747541584076\n",
      "242 37.6194890600018 0.015607377959415317 0.016024288162589072 0.050724620022810994 0.05302715890109539\n",
      "243 37.94680406799307 0.015605079185217618 0.01603695209417492 0.05024752852041274 0.0525517117837444\n",
      "244 37.681819359000656 0.015512653038371354 0.01589118398563005 0.04938664698973298 0.051733399727381765\n",
      "245 37.51299787800235 0.015722881925292313 0.01613391580292955 0.04968333681114018 0.05204035886563361\n",
      "246 37.5734483779961 0.01572993179410696 0.016131482211174445 0.049940204499289396 0.05229064258746803\n",
      "247 37.68979750700237 0.015612662099767477 0.016009932402987034 0.050574143631383774 0.05300748202949762\n",
      "248 37.48537980800029 0.015976466255728156 0.016377731259446592 0.047869607810862365 0.05005187680013478\n",
      "249 37.5619136759924 0.015576572511577978 0.015970747417537495 0.048323061401024464 0.05061893332749605\n",
      "250 37.478935443999944 0.015573455441277475 0.015981809309218078 0.04877792343497276 0.0510666936263442\n",
      "251 37.618562664007186 0.015501836064504459 0.015895798361860215 0.04995034901890904 0.05215099166613072\n",
      "252 37.53708079199714 0.015224322342779487 0.015626048107631504 0.0491974671324715 0.051417099642567334\n",
      "253 37.53665220399853 0.015761977308429778 0.016176218643318863 0.05038644512649625 0.05260705436114222\n",
      "254 37.7295848979993 0.015608567841351033 0.01600214731320739 0.049123084149323405 0.05132805683650076\n",
      "255 37.6065740960039 0.015285820659715682 0.015704328109044582 0.04929359412752092 0.05160128165502101\n",
      "256 37.58497622499999 0.01568606545124203 0.016106870104558767 0.04728851563297212 0.04946983410976827\n",
      "257 37.878540635996615 0.015659889948554336 0.016076654293341562 0.049239938189275564 0.05145154863130301\n",
      "258 37.62540035699203 0.015552171445917338 0.015945432434789835 0.04753129620105028 0.04964418780524284\n",
      "259 37.562616173003335 0.01574096503574401 0.01614468945679255 0.04881561280693859 0.0509858714742586\n",
      "260 37.5322668190056 0.015736801016144455 0.01616805926710367 0.04810310774017126 0.050289488499984145\n",
      "261 36.562553570998716 0.015566548698348925 0.015968365621520205 0.04876720448955894 0.050952744726091626\n",
      "262 37.42967133199272 0.015578625576104968 0.015983357785269617 0.047484370740130545 0.04979345060884952\n",
      "263 37.45868129399605 0.015487034427700564 0.015885500699281692 0.04845051364041865 0.050682487934827804\n",
      "264 38.05326642400178 0.015516058469424025 0.01592608199082315 0.04903410404920578 0.05108855161815882\n",
      "265 37.908015806999174 0.015178728426340967 0.01557811408280395 0.049219774757511915 0.05123737083747983\n",
      "266 37.58419980799954 0.01556255215825513 0.01598201150400564 0.04786146173253655 0.05003001905977726\n",
      "267 37.74849159800215 0.01556312425271608 0.015980281193973496 0.04896776373498142 0.05106430372223258\n",
      "268 37.52552131500852 0.01559492074791342 0.015997638293076308 0.04786337467841804 0.05007895611226559\n",
      "269 37.386822422995465 0.015286060889717191 0.01572562455246225 0.04755381129682064 0.04968935227487236\n",
      "270 37.74442759998783 0.015470927860587836 0.015877736181020737 0.050203863326460124 0.05227011329028755\n",
      "271 37.37541824398795 0.015514441892504692 0.01590999741666019 0.04901516518555581 0.05106678714510053\n",
      "272 37.44079363200581 0.01540612477157265 0.015818994701839985 0.04674897967837751 0.048728141728788615\n",
      "273 37.6143506619992 0.01544389649736695 0.015845801616087556 0.04647140653338283 0.04842295076232404\n",
      "274 37.656233176996466 0.015305693331640214 0.015727940494194625 0.04870501487050206 0.05086194443982094\n",
      "275 37.572807930002455 0.01588299323548563 0.0162889901867602 0.048092806409113106 0.05007776801474392\n",
      "276 37.6008617769985 0.015616755201015622 0.01601480069896206 0.049301741272211076 0.05122169133741408\n",
      "277 35.77742208700511 0.015802194324787706 0.01619645028328523 0.048695238940417766 0.050738787818700073\n",
      "278 37.48029329000565 0.01548749697720632 0.01588355980766937 0.048020414453931154 0.04994735093321651\n",
      "279 37.68881803100521 0.015703367930371314 0.016099593084771185 0.049010125352069736 0.051051828507333995\n",
      "280 34.99312661400472 0.015351220120675862 0.01574940752144903 0.049772297856397925 0.051900285882875326\n",
      "281 37.705608468997525 0.015391884013777599 0.015800610011909157 0.04695878036320209 0.04911546034738421\n",
      "282 36.75516723700275 0.015294779473915696 0.01571452409331687 0.04774031658656895 0.04980730299837887\n",
      "283 37.14660589599225 0.015196382484864443 0.015588797816308215 0.048626880440860984 0.050601379219442605\n",
      "284 37.439178462998825 0.015452118180226534 0.01585437816241756 0.05113455664832145 0.052980212685652076\n",
      "285 37.67329849599628 0.015447215801337734 0.015856849997770043 0.048000943195074794 0.050116851329803466\n",
      "286 37.405260279992945 0.015365542427171022 0.015768716440768913 0.04808740776963532 0.05004430369939655\n",
      "287 37.42045357299503 0.015466191944899038 0.01585795880970545 0.04765626644250005 0.04960789698176086\n",
      "288 37.415259653003886 0.0159195051882416 0.016334571912419053 0.04770630849525333 0.04974580905865878\n",
      "289 36.05836537400319 0.015610795503482223 0.01602407288691029 0.047340777218341824 0.04930007038637996\n",
      "290 36.95878922801057 0.01567783865565434 0.016059121147962287 0.04818073757924139 0.05029212961439043\n",
      "291 37.507239354003104 0.015279065124690532 0.015666495182551445 0.04788254004903138 0.049859432596713306\n",
      "292 37.56548039900372 0.015579432092607022 0.01599260477651842 0.04846995551139116 0.05043783640488982\n",
      "293 37.46727507500327 0.015376870413776488 0.015780129158403725 0.04739036752376705 0.04934725427534431\n",
      "294 37.5115735349973 0.015458079407690093 0.01588532474078238 0.049266537157818674 0.05136441586539149\n",
      "295 37.67211445599969 0.015476208070060239 0.015874494530959054 0.04636279636994004 0.04831535814795643\n",
      "296 37.48185685899807 0.015227922222577035 0.015624608067329973 0.047908273269422354 0.04967457443010062\n",
      "297 37.557022092005354 0.015599015530664473 0.01600172505667433 0.04661468385718763 0.048447028030641374\n",
      "298 37.61596633399313 0.015413407201878726 0.015823329754173755 0.04854949610773474 0.05058793544303626\n",
      "299 37.42748389299959 0.01528521445649676 0.01568950331839733 0.04700286093633622 0.04902094851713627\n",
      "300 37.52754517800349 0.012194822325836867 0.012460866218665614 0.047761445958167316 0.049676692155189814\n",
      "301 36.02834106198861 0.01200829888996668 0.012279891095357015 0.04721525246277451 0.0491075241426006\n",
      "302 38.00299578100385 0.011962156381690875 0.012234900987008586 0.04673042622860521 0.04865801962092519\n",
      "303 37.35982498800149 0.012081776706269011 0.012344975482439622 0.04664801384788007 0.04851591756567359\n",
      "304 37.3511777859967 0.012094702698756008 0.0123752248887904 0.04830602059140801 0.05019308159127831\n",
      "305 37.484024787001545 0.011854108284693212 0.012123001656262204 0.04686986952088773 0.04868618791922927\n",
      "306 37.10252460000629 0.01200073629943654 0.012264583432115615 0.04671755821909755 0.048547366666607555\n",
      "307 37.375992646993836 0.011862923839362337 0.012131421824684366 0.047032618126831946 0.04886235611047596\n",
      "308 37.19598759699147 0.011777026693336665 0.012047640768811107 0.04705738989636302 0.04885794499423355\n",
      "309 37.52802104600414 0.011843632399803027 0.012106070713605732 0.0462626210320741 0.04799852257594466\n",
      "310 37.36912102399219 0.011811144569190218 0.012082454189658165 0.04557585949078202 0.04735683543141931\n",
      "311 37.34118354400562 0.011719272391172125 0.011987099404446781 0.045550074367783966 0.04729715121909976\n",
      "312 33.7551123680023 0.011833100588060915 0.012110379939433187 0.04632327902596444 0.048085087230429056\n",
      "313 37.62644186300167 0.011779922649031506 0.012052381177200004 0.04544866248033941 0.04719727896619588\n",
      "314 37.41379175901238 0.011749015886336565 0.012019592250930146 0.046190436999313536 0.04792280576191842\n",
      "315 35.225309747998836 0.011884834165452048 0.012168907456099987 0.04551940490957349 0.04718358204700053\n",
      "316 34.109598177994485 0.011769018133403733 0.012042827375698834 0.045203967937268316 0.04695362178608775\n",
      "317 35.0771684700012 0.012132688895100727 0.012419804618228227 0.04618106010835618 0.04792529567144811\n",
      "318 37.47128053600318 0.011843285064445808 0.01211382078868337 0.046411776174791156 0.04813680192921311\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "319 37.441661805991316 0.011575568135362119 0.011842807365581394 0.045790949366055426 0.047463819300755855\n",
      "320 37.45280774199637 0.011681953271385282 0.011954784823581576 0.04588805203326046 0.04765141657087952\n",
      "321 37.35219816099561 0.011811963323503732 0.01208187802741304 0.0472404720261693 0.04897529166657478\n",
      "322 37.54948165800306 0.01175030776602216 0.01202919317339547 0.046343565792776646 0.047972823209129274\n",
      "323 36.655121431002044 0.011758755278075114 0.012030958950519562 0.04529581900220364 0.04699986042454839\n",
      "324 37.17967567899905 0.011641712277662008 0.011919186796527356 0.045950199477374554 0.04759293383918703\n",
      "325 37.577082326999516 0.011706781913060694 0.011970596643164754 0.04652690504211932 0.048195860972628\n",
      "326 37.50193164499069 0.011675486621214077 0.011960330336820334 0.045114258299581704 0.04681364716496319\n",
      "327 37.405144017000566 0.011672837302321569 0.011938574668485672 0.04445018329191953 0.04611197818536311\n",
      "328 37.48708146699937 0.011528158620465547 0.01179769020038657 0.04482979593798518 0.04649553609546274\n",
      "329 37.7230369720055 0.011681283426471055 0.011957750463159755 0.04396490077953786 0.04555705100297928\n",
      "330 35.949039625003934 0.011678792040562257 0.011952103066025302 0.044533405657857655 0.046195303318090734\n",
      "331 35.597594598992146 0.011613044605357573 0.011884882075013594 0.044184559397399424 0.045837449575774375\n",
      "332 36.55735115001153 0.011797310067340732 0.012073131958255543 0.04666219514794648 0.04820071056950837\n",
      "333 36.30188188099419 0.01151250072591938 0.011774014954920859 0.044005380128510296 0.04563922598958015\n",
      "334 37.327844611005276 0.011916912598768249 0.012193577190861105 0.044497109688818454 0.046082232650369405\n",
      "335 38.12866285099881 0.011707757434807719 0.011993191516958178 0.045145905711688104 0.046766472961753604\n",
      "336 37.47482478599704 0.011659992226865142 0.01193718814640306 0.04453325893729925 0.046176261403597894\n",
      "337 37.55998245900264 0.011654070939170197 0.011910921156639232 0.044881275184452535 0.046524480707012116\n",
      "338 37.579256468001404 0.011560733584687113 0.011836940949317068 0.044564858502708374 0.04618097573984414\n",
      "339 37.794217529008165 0.011651563891675324 0.011927064585033804 0.04486132175195962 0.04648032755125314\n",
      "340 37.45395705199917 0.011932934554992244 0.012216721710981801 0.044516927041113374 0.04615027027204633\n",
      "341 37.61718808999285 0.011441001274390145 0.011713703448651358 0.04440272094216198 0.046033062255010006\n",
      "342 37.54038118298922 0.011567943737609311 0.011833102686796337 0.04428659336641431 0.04584392867516726\n",
      "343 37.66716852100217 0.011641695071943105 0.011915305805625394 0.04545647131279111 0.04702563872095197\n",
      "344 37.60330206301296 0.011615570664871485 0.011882739803753792 0.04446471940726042 0.04595227084122598\n",
      "345 37.65715168000315 0.011588146208552644 0.011863076714100316 0.04438729373272508 0.046026484523899854\n",
      "346 37.46370205799758 0.011565431992989034 0.011833040613681078 0.04664707394316792 0.04817213944159448\n",
      "347 37.49582139200356 0.011442761209560557 0.011709114306839182 0.04450733317062259 0.04613166335970163\n",
      "348 37.30706892500166 0.011620448799571022 0.011903615739196538 0.044088641600683334 0.045715581667609514\n",
      "349 37.34504455298884 0.011981563830981031 0.012272865413920954 0.04414341021329164 0.04570259976200759\n",
      "350 37.52366845800134 0.01138868173561059 0.011657216621097177 0.04425702933687717 0.0458241955563426\n",
      "351 37.52282794500934 0.011532781000714748 0.011799522269051522 0.042933519333601 0.044506318704225126\n",
      "352 37.35727215500083 0.011493024258641526 0.011773115115007386 0.044740193472243846 0.046163149760104716\n",
      "353 38.15530714800116 0.011674957722425461 0.011952691443264484 0.04389056456740945 0.0455147104524076\n",
      "354 37.71953726299398 0.011573551554232836 0.01185765870870091 0.0437409940129146 0.04526915178634226\n",
      "355 35.67972095699224 0.011605735768796876 0.011885112209012732 0.04385275315493345 0.04538784065749496\n",
      "356 37.66020373599895 0.011744632640155033 0.012034595594974235 0.04269306492060423 0.04423053227365017\n",
      "357 37.45684825400531 0.01147421874338761 0.011740095857298002 0.04375936371739954 0.045309719177894295\n",
      "358 37.64901672999258 0.011559926698449999 0.011836951252771542 0.044113089446909726 0.04558884663507343\n",
      "359 37.41366373600613 0.011620973935816436 0.01190904527483508 0.04331670950632542 0.044917058376595376\n",
      "360 37.83523888399941 0.011806755841709673 0.012102652467787266 0.04374311852734536 0.045311863641254606\n",
      "361 37.91905394800415 0.011360896575730294 0.011621680794283747 0.04505434688180685 0.046576214474625885\n",
      "362 37.91783220700745 0.011505672650644555 0.011779981130035594 0.04499874835833907 0.04650730310939252\n",
      "363 37.66563394200057 0.011658859263174236 0.011938666792586445 0.04344252086710185 0.04495241818018258\n",
      "364 37.774252505012555 0.0116764492909424 0.011950778763741255 0.04368105728179216 0.04520118332933634\n",
      "365 37.72367592000228 0.011663826574804262 0.01195588659052737 0.04364038789644838 0.04523043402470648\n",
      "366 37.42111485800706 0.01160299533396028 0.011889347162563353 0.04330142891965807 0.0448668308975175\n",
      "367 37.55467186299211 0.011728389624273404 0.012008523422991857 0.04221485623624176 0.043669845666736366\n",
      "368 37.76395444299851 0.011790681617567316 0.012077857714844868 0.04315141220577061 0.04461222073528916\n",
      "369 37.54575261598802 0.011405565013177693 0.011680570370750501 0.043833120400086044 0.045337946503423154\n",
      "370 37.66647343199293 0.011485848495038226 0.01176088040554896 0.04380358893889934 0.04531496364623308\n",
      "371 37.44127304200083 0.01156008340511471 0.011841430455213412 0.044655262515880166 0.04608653964940459\n",
      "372 37.536014930999954 0.011345905631082133 0.011627841969486326 0.042817523297853766 0.0443050922639668\n",
      "373 37.40095246498822 0.011578024303540588 0.011861492337659001 0.042757895877584814 0.044257517592050134\n",
      "374 37.59051190500031 0.0113521718964912 0.011638525172835215 0.04320701954420656 0.04467850157991052\n",
      "375 37.228586201992584 0.011342079871566966 0.011608107835520059 0.04336952656041831 0.044786421805620195\n",
      "376 37.0105789819936 0.011705924710026011 0.011984144260874017 0.04319459426216781 0.04463761943392455\n",
      "377 37.699305433998234 0.011608099749544635 0.011894741686992347 0.04360074857249856 0.045138517944142226\n",
      "378 37.57852906000335 0.011462414478417487 0.011733283416600898 0.04366533151362091 0.04510896452702582\n",
      "379 37.483487282996066 0.011478739815298468 0.011761229386087507 0.042666839179582895 0.04411436105612666\n",
      "380 37.66770389500016 0.01147147329733707 0.011747572644380852 0.04245456978213042 0.04398374831769616\n",
      "381 37.67936501800432 0.011475193741265684 0.011743044372880831 0.04318807200994343 0.04467640482354909\n",
      "382 37.44653977200505 0.011390994865680114 0.011673093877499922 0.04345593736506999 0.04498334162402898\n",
      "383 35.52694718798739 0.011392296820878983 0.011685713278828188 0.0432892306195572 0.04471916775684804\n",
      "384 37.55948857800104 0.011447506572352722 0.011732986769173294 0.04246401310432702 0.04391906218137592\n",
      "385 38.083759957997245 0.011546113024931401 0.011817707806825638 0.043887767270207406 0.04532185645774007\n",
      "386 37.98850458400557 0.011446167187299579 0.01172451867791824 0.04254344071261585 0.043935691458173096\n",
      "387 38.08019543498813 0.011668582102516666 0.011955711770802737 0.042142056613229215 0.04357143229339272\n",
      "388 37.53162759200495 0.011309341724030673 0.011585199128370732 0.04328915711026639 0.044659768175333736\n",
      "389 37.6447665040032 0.011486784538021311 0.011766289178747684 0.042624462954699995 0.04397504656109959\n",
      "390 37.48500741900352 0.0114315742761828 0.0117193500821013 0.04334899733774364 0.04478596582543105\n",
      "391 37.27610030899814 0.01143294417927973 0.01171549806650728 0.04322219755034894 0.044717435273341835\n",
      "392 37.604464688003645 0.011535254182992503 0.011828091928735376 0.04215796091593802 0.04350046888459474\n",
      "393 37.51677924999967 0.01142032326036133 0.011695960801793262 0.04242261099629104 0.04385184537619352\n",
      "394 37.503651965002064 0.011349266148172318 0.01161097053089179 0.04155828081071377 0.042990013975650075\n",
      "395 37.33931048600061 0.011420280387392267 0.011705249866470695 0.0420741627831012 0.043517704452387986\n",
      "396 37.18153205201088 0.01113140331604518 0.011412244009086862 0.04244836277794093 0.04378761125728488\n",
      "397 37.30406256299466 0.011455395889934153 0.011739320437191053 0.04347806221339852 0.044857952622696755\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398 37.4997773340001 0.011491305708419532 0.011776332583278417 0.042243880801834166 0.04362450065556914\n",
      "399 37.63056781400519 0.011413158765295521 0.011693040956277401 0.04234240132384002 0.04374241141602397\n",
      "400 37.5410479830025 0.00942485629604198 0.009615845763357356 0.042596731879748405 0.04393608387093991\n",
      "401 37.5860365289991 0.009358518529916182 0.009542685653083026 0.043068398493342104 0.04440975723322481\n",
      "402 37.340352370010805 0.009326255577383563 0.00951489898446016 0.04280638671480119 0.0441350009245798\n",
      "403 37.55376783700194 0.009384810558985919 0.009578738931100816 0.04198799685575068 0.043347430774010716\n",
      "404 37.317179638994276 0.0092888173032552 0.009476377652958036 0.04328293187078089 0.04460384063888341\n",
      "405 38.063680585997645 0.009280548786045983 0.00947114520217292 0.04337089715059847 0.044717081123963\n",
      "406 38.135504789999686 0.009346276646712795 0.009534614796983079 0.04231380494311452 0.04364928556140512\n",
      "407 37.93574082799023 0.009142969794105739 0.009323594520101324 0.04274497104808688 0.04408966310322285\n",
      "408 37.50975290300266 0.009335545496782288 0.009527436697622762 0.04321122263092548 0.04455864259041846\n",
      "409 37.946244891005335 0.009186651818454265 0.009371759277768434 0.04259609245229513 0.04394290667958558\n",
      "410 37.92453058299725 0.009196647910634057 0.009380076616769657 0.043059477657079695 0.044401451819576325\n",
      "411 37.642724159988575 0.009258926733862608 0.009443982841446995 0.04316318391822278 0.04443604125175625\n",
      "412 38.069205784995575 0.009303510057041421 0.009498838210478425 0.04209860805887729 0.04341706142295152\n",
      "413 37.409212969010696 0.009155010184738785 0.009347400394501165 0.04416999073699117 0.04540892358869314\n",
      "414 37.48586549999891 0.009151461080182343 0.009330942898290232 0.0433785798586905 0.04469572656787932\n",
      "415 37.582100005005486 0.009275915498845278 0.009476495193783194 0.04274889730382711 0.04409170371480286\n",
      "416 33.81786449599895 0.00909252862795256 0.009275978679768742 0.04327378902118653 0.04456861348357052\n",
      "417 35.856732155996724 0.009040047373622656 0.009224318486871198 0.04288023726548999 0.04421013954561204\n",
      "418 37.02426565000496 0.009154886292526499 0.009345778785878792 0.04263846071437001 0.043968553147278724\n",
      "419 37.45932322500448 0.009161232399754226 0.009352675120811909 0.04391477423720062 0.045245495419949294\n",
      "420 37.538743176992284 0.009079983482137323 0.009266714487690479 0.04361038020346314 0.044924425939098\n",
      "421 37.477654135989724 0.009145564540289343 0.009344083715463056 0.04296812087297439 0.04427843114361167\n",
      "422 35.024656326000695 0.009143437139922753 0.009334559215931222 0.04342611784581095 0.04473481784109026\n",
      "423 37.43821098799526 0.009064291710499673 0.009256346950540319 0.04263404715806246 0.04396387246903032\n",
      "424 37.367696052999236 0.009075059515656904 0.00926199820265174 0.04341583143454045 0.04472110463306308\n",
      "425 37.67293286399217 0.00924026671377942 0.009431893711676822 0.042502689869143066 0.043837189814075826\n",
      "426 37.58494258999417 0.009004792171763256 0.009198460853192956 0.04267302244901657 0.04399085361044854\n",
      "427 37.68977364701277 0.009058819394093007 0.009246083948295564 0.04309730269480497 0.04440540500450879\n",
      "428 38.231107005995 0.009054486114066094 0.009245645471150055 0.043054323345422744 0.044363766070455314\n",
      "429 38.04373767900688 0.009140405792044476 0.00933089599199593 0.04305495677981526 0.044361461531370876\n",
      "430 38.021198321992415 0.009021264686249196 0.00920463158772327 0.04303967202547938 0.04438509983941913\n",
      "431 38.227394911999 0.009098947505699471 0.00928834064421244 0.04295031899120658 0.0442408256419003\n",
      "432 38.31364726200991 0.009014142886735499 0.009203147238353268 0.04265671470668167 0.043953684689477086\n",
      "433 37.63577755000733 0.00898518711188808 0.009181305249221623 0.043085431945510205 0.044400357180275025\n",
      "434 37.425399510000716 0.009082470911554992 0.009278217162471264 0.04339380306657404 0.04465415420942009\n",
      "435 37.52172342300764 0.009117298556258901 0.009312235441757365 0.04323730210773647 0.044513926012441515\n",
      "436 37.51868793400354 0.009063062533270567 0.00925396389234811 0.043886506292037664 0.045177054186351595\n",
      "437 37.51384340999357 0.009024153168546037 0.009214206177275627 0.043363790367729964 0.04466180293355137\n",
      "438 37.54849220300093 0.00896527421916835 0.009156453389441594 0.043160389559343454 0.044444104544818404\n",
      "439 37.54378596400784 0.009153846541652456 0.009342261939076706 0.04329055035952479 0.044552843384444714\n",
      "440 37.63668536199839 0.00899493726529181 0.00919227953464724 0.04267367480322719 0.04396153980866074\n",
      "441 37.467092355989735 0.00897456726548262 0.009164586294442416 0.04239278496708721 0.043663670420646665\n",
      "442 37.320264098001644 0.00898673092527315 0.009177328618243337 0.04401796711608767 0.045227903705090285\n",
      "443 37.450026392005384 0.009141510823043063 0.009335005594184622 0.04287069384008646 0.0441684859059751\n",
      "444 36.70112539199181 0.009064580789534375 0.009258464958984405 0.043324304474517704 0.0446091407071799\n",
      "445 37.56427483299922 0.00900546065135859 0.009197571319062263 0.04299264557659626 0.04426667008548975\n",
      "446 37.57356158399489 0.008929215693380683 0.0091175441541709 0.04321467136964202 0.04448402760084719\n",
      "447 37.44640080399404 0.008957808943698183 0.00914944380079396 0.04312591826543212 0.0443842539889738\n",
      "448 37.48442288499791 0.0089200534732081 0.009110801869072021 0.043427254860289394 0.0446750093344599\n",
      "449 36.69121695499052 0.008936597841326147 0.009120037070475519 0.04309332396835089 0.044338882933370766\n",
      "450 37.466712941997685 0.009041088223690166 0.009232444040942938 0.04309524354990572 0.044346876344643536\n",
      "451 37.50890179400449 0.009022744328482076 0.009216780595947056 0.043122671549208465 0.04437018753960729\n",
      "452 37.46813440299593 0.008935180318308995 0.009121359456563368 0.0423564026504755 0.04362729356158525\n",
      "453 37.42063712399977 0.00894273945945315 0.009137888093478978 0.042789845895022154 0.044067270657978955\n",
      "454 35.18535472199437 0.009011131359264254 0.00920568900485523 0.0430992214102298 0.044365490665659306\n",
      "455 37.10391370700381 0.008814311438240111 0.00900090718199499 0.04259470433462411 0.043881804537959396\n",
      "456 38.010593138998956 0.008884006439009681 0.009069975236663594 0.044048210401088 0.04530764043331146\n",
      "457 37.40614161299891 0.00894487277069129 0.00913711711904034 0.04313260882627219 0.04441086158622056\n",
      "458 37.506961621998926 0.008961790704168379 0.009145268922438846 0.0424213717924431 0.04368205477483571\n",
      "459 37.65256052000041 0.008921671797754244 0.009119648714084178 0.04277103649452329 0.04398269918281585\n",
      "460 38.00992082800076 0.008888981770025567 0.009082068354589865 0.04348185191862285 0.044676969489082695\n",
      "461 38.15624830700108 0.008989673532312736 0.009171965565765277 0.04319104618392885 0.044475633120164275\n",
      "462 37.85963773200638 0.00890570784616284 0.009094074974302202 0.042573196534067395 0.043849837677553294\n",
      "463 37.66319860499061 0.008934021087130532 0.009132603044854477 0.04330171697307378 0.04452711780089885\n",
      "464 37.42463898300775 0.008869728070450947 0.009065921624656767 0.04235219262074679 0.04358933701645583\n",
      "465 37.404938870007754 0.008894959396333434 0.009081101736053825 0.04326007438357919 0.044519105539657176\n",
      "466 36.13518840400502 0.008959082311252132 0.009151724093593657 0.04344123722519726 0.0447422358719632\n",
      "467 34.39449975200114 0.008962768950965256 0.009155145143624395 0.04308976573869586 0.04433902934193611\n",
      "468 37.55925391099299 0.008870378776919097 0.009060837398748845 0.042905798507854344 0.04414990372490138\n",
      "469 37.612198283997714 0.009041350653395057 0.009235674757976086 0.042818316561169925 0.044063184959813956\n",
      "470 37.453993567003636 0.008998553346376866 0.009185191651107743 0.042231535096652804 0.04346248175017536\n",
      "471 37.498085743005504 0.00880314745591022 0.008998078138567508 0.04226773972157389 0.04348615118302405\n",
      "472 37.23285397500149 0.008930817083921284 0.009119921084260569 0.04317340884823352 0.044415413280948994\n",
      "473 37.675606837001396 0.008865866520674899 0.00905571667419281 0.043465220010839405 0.044683854915201666\n",
      "474 37.71147485100664 0.008878517020726576 0.009074160134186968 0.04180530012119561 0.043056729612872005\n",
      "475 37.5301874029974 0.008873853721190244 0.009061569522833452 0.04341180301271379 0.04459025360178202\n",
      "476 37.056272048997926 0.008893042498733848 0.009084491037530824 0.04200538599397987 0.04320360321551561\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "477 37.79613288800465 0.008857273531612008 0.00905586438975297 0.04267853506375104 0.043928272402845324\n",
      "478 37.62502300000051 0.008767531829653308 0.008954925556201488 0.04287892064545304 0.044108998496085405\n",
      "479 37.26595963000727 0.008950260508339853 0.009149293887894601 0.043067218181677164 0.04431315880268812\n",
      "480 37.654457276003086 0.008866188909392805 0.009063081626431085 0.04327726666815579 0.044503894853405654\n",
      "481 37.50488031699206 0.008863316526869312 0.009050029962789268 0.04318904687184841 0.044406088166870174\n",
      "482 37.664560727993376 0.008840830168221146 0.009033685553236864 0.04196514209266752 0.04317535526119173\n",
      "483 37.62037392199272 0.008763918036827818 0.0089472558114212 0.04301288319285959 0.044211823889054355\n",
      "484 37.429969189994154 0.008767901436425746 0.008956682387040928 0.04252258236519992 0.04376926614437252\n",
      "485 37.80207029799931 0.008871357984142379 0.00906225029216148 0.04280390663072467 0.044043415170162914\n",
      "486 37.996363782003755 0.008806250913534314 0.00900025088666007 0.04312843377701938 0.04433211019728333\n",
      "487 37.604724505989 0.008895840187557041 0.009099155480624177 0.042403556723147634 0.04365280267782509\n",
      "488 36.0061696729972 0.00887439923803322 0.009070090017048641 0.04316171881742775 0.044325006394647065\n",
      "489 37.762223106998135 0.008858097374439239 0.009048068074509502 0.042099839546717706 0.04326636309269816\n",
      "490 34.24322592499084 0.008903017582837493 0.009108187840553 0.04314934277441353 0.04438711498863995\n",
      "491 36.129722891011625 0.008771877141669392 0.008960073028458282 0.04347185518592596 0.044691521809436384\n",
      "492 37.62031045499316 0.00870995197049342 0.008902799847302958 0.0424399714358151 0.04367008370347321\n",
      "493 37.61985542099865 0.008941944568883628 0.009134860137244686 0.042538649691268804 0.04373352174181491\n",
      "494 37.61071305599762 0.008867084530182184 0.009057734241243452 0.043414693940430876 0.044690028559416534\n",
      "495 37.56969984101306 0.008858804286923259 0.00905977654014714 0.04260330587159842 0.04379365953151137\n",
      "496 37.367754695005715 0.00878975020069629 0.00898291769507341 0.042339049987494944 0.04351303419563919\n",
      "497 37.599725009000394 0.008815628060139715 0.009007843935396522 0.04241961031686515 0.04359645735006779\n",
      "498 37.783630778008956 0.008874869004124776 0.009072695911629125 0.041782193551771346 0.04299818794243038\n",
      "499 37.45439367899962 0.008761427954537795 0.008948082103626803 0.04256909714080393 0.04376272790133953\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'model/ns_fourier_2d_rnn_V10000_T20_N1000_ep500_m12_w20'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-49263348932d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    320\u001b[0m           test_l2_full / ntest)\n\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    367\u001b[0m     \u001b[0m_check_dill_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_use_new_zipfile_serialization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'model/ns_fourier_2d_rnn_V10000_T20_N1000_ep500_m12_w20'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "@author: Zongyi Li\n",
    "This file is the Fourier Neural Operator for 2D problem such as the Navier-Stokes equation discussed in Section 5.3 in the [paper](https://arxiv.org/pdf/2010.08895.pdf),\n",
    "which uses a recurrent structure to propagates in time.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import gc\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from utilities3 import *\n",
    "\n",
    "import operator\n",
    "from functools import reduce\n",
    "from functools import partial\n",
    "\n",
    "from timeit import default_timer\n",
    "import scipy.io\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "#Complex multiplication\n",
    "def compl_mul2d(a, b):\n",
    "    op = partial(torch.einsum, \"bctq,dctq->bdtq\")\n",
    "    return torch.stack([\n",
    "        op(a[..., 0], b[..., 0]) - op(a[..., 1], b[..., 1]),\n",
    "        op(a[..., 1], b[..., 0]) + op(a[..., 0], b[..., 1])\n",
    "    ], dim=-1)\n",
    "\n",
    "################################################################\n",
    "# fourier layer\n",
    "################################################################\n",
    "\n",
    "class SpectralConv2d_fast(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, modes1, modes2):\n",
    "        super(SpectralConv2d_fast, self).__init__()\n",
    "\n",
    "        \"\"\"\n",
    "        2D Fourier layer. It does FFT, linear transform, and Inverse FFT.    \n",
    "        \"\"\"\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.modes1 = modes1 #Number of Fourier modes to multiply, at most floor(N/2) + 1\n",
    "        self.modes2 = modes2\n",
    "\n",
    "        self.scale = (1 / (in_channels * out_channels))\n",
    "        self.weights1 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, 2))\n",
    "        self.weights2 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, 2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        batchsize = x.shape[0]\n",
    "        #Compute Fourier coeffcients up to factor of e^(- something constant)\n",
    "        x_ft = torch.rfft(x, 2, normalized=True, onesided=True)\n",
    "\n",
    "        # Multiply relevant Fourier modes\n",
    "        out_ft = torch.zeros(batchsize, self.in_channels, x.size(-2), x.size(-1)//2 + 1, 2, device=x.device)\n",
    "        out_ft[:, :, :self.modes1, :self.modes2] = \\\n",
    "            compl_mul2d(x_ft[:, :, :self.modes1, :self.modes2], self.weights1)\n",
    "        out_ft[:, :, -self.modes1:, :self.modes2] = \\\n",
    "            compl_mul2d(x_ft[:, :, -self.modes1:, :self.modes2], self.weights2)\n",
    "\n",
    "        #Return to physical space\n",
    "        x = torch.irfft(out_ft, 2, normalized=True, onesided=True, signal_sizes=(x.size(-2), x.size(-1)))\n",
    "        return x\n",
    "\n",
    "class SimpleBlock2d(nn.Module):\n",
    "    def __init__(self, modes1, modes2, width):\n",
    "        super(SimpleBlock2d, self).__init__()\n",
    "\n",
    "        \"\"\"\n",
    "        The overall network. It contains 4 layers of the Fourier layer.\n",
    "        1. Lift the input to the desire channel dimension by self.fc0 .\n",
    "        2. 4 layers of the integral operators u' = (W + K)(u).\n",
    "            W defined by self.w; K defined by self.conv .\n",
    "        3. Project from the channel space to the output space by self.fc1 and self.fc2 .\n",
    "        \n",
    "        input: the solution of the previous 10 timesteps + 2 locations (u(t-10, x, y), ..., u(t-1, x, y),  x, y)\n",
    "        input shape: (batchsize, x=64, y=64, c=12)\n",
    "        output: the solution of the next timestep\n",
    "        output shape: (batchsize, x=64, y=64, c=1)\n",
    "        \"\"\"\n",
    "\n",
    "        self.modes1 = modes1\n",
    "        self.modes2 = modes2\n",
    "        self.width = width\n",
    "        self.fc0 = nn.Linear(12, self.width)\n",
    "        # input channel is 12: the solution of the previous 10 timesteps + 2 locations (u(t-10, x, y), ..., u(t-1, x, y),  x, y)\n",
    "\n",
    "        self.conv0 = SpectralConv2d_fast(self.width, self.width, self.modes1, self.modes2)\n",
    "        self.conv1 = SpectralConv2d_fast(self.width, self.width, self.modes1, self.modes2)\n",
    "        self.conv2 = SpectralConv2d_fast(self.width, self.width, self.modes1, self.modes2)\n",
    "        self.conv3 = SpectralConv2d_fast(self.width, self.width, self.modes1, self.modes2)\n",
    "        self.w0 = nn.Conv1d(self.width, self.width, 1)\n",
    "        self.w1 = nn.Conv1d(self.width, self.width, 1)\n",
    "        self.w2 = nn.Conv1d(self.width, self.width, 1)\n",
    "        self.w3 = nn.Conv1d(self.width, self.width, 1)\n",
    "        self.bn0 = torch.nn.BatchNorm2d(self.width)\n",
    "        self.bn1 = torch.nn.BatchNorm2d(self.width)\n",
    "        self.bn2 = torch.nn.BatchNorm2d(self.width)\n",
    "        self.bn3 = torch.nn.BatchNorm2d(self.width)\n",
    "\n",
    "\n",
    "        self.fc1 = nn.Linear(self.width, 128)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batchsize = x.shape[0]\n",
    "        size_x, size_y = x.shape[1], x.shape[2]\n",
    "\n",
    "        x = self.fc0(x)\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "\n",
    "        x1 = self.conv0(x)\n",
    "        x2 = self.w0(x.view(batchsize, self.width, -1)).view(batchsize, self.width, size_x, size_y)\n",
    "        x = self.bn0(x1 + x2)\n",
    "        x = F.relu(x)\n",
    "        x1 = self.conv1(x)\n",
    "        x2 = self.w1(x.view(batchsize, self.width, -1)).view(batchsize, self.width, size_x, size_y)\n",
    "        x = self.bn1(x1 + x2)\n",
    "        x = F.relu(x)\n",
    "        x1 = self.conv2(x)\n",
    "        x2 = self.w2(x.view(batchsize, self.width, -1)).view(batchsize, self.width, size_x, size_y)\n",
    "        x = self.bn2(x1 + x2)\n",
    "        x = F.relu(x)\n",
    "        x1 = self.conv3(x)\n",
    "        x2 = self.w3(x.view(batchsize, self.width, -1)).view(batchsize, self.width, size_x, size_y)\n",
    "        x = self.bn3(x1 + x2)\n",
    "\n",
    "\n",
    "        x = x.permute(0, 2, 3, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "class Net2d(nn.Module):\n",
    "    def __init__(self, modes, width):\n",
    "        super(Net2d, self).__init__()\n",
    "\n",
    "        \"\"\"\n",
    "        A wrapper function\n",
    "        \"\"\"\n",
    "\n",
    "        self.conv1 = SimpleBlock2d(modes, modes, width)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "    def count_params(self):\n",
    "        c = 0\n",
    "        for p in self.parameters():\n",
    "            c += reduce(operator.mul, list(p.size()))\n",
    "\n",
    "        return c\n",
    "\n",
    "\n",
    "################################################################\n",
    "# configs\n",
    "################################################################\n",
    "#TRAIN_PATH = 'data/NavierStokes_V1e-5_N1200_T20.mat'\n",
    "#TEST_PATH = 'data/NavierStokes_V1e-5_N1200_T20.mat'\n",
    "TRAIN_PATH = 'data/Vortex_dynamics_64_64_grid.mat'\n",
    "TEST_PATH = 'data/Vortex_dynamics_64_64_grid.mat'\n",
    "\n",
    "ntrain = 1000\n",
    "ntest = 200\n",
    "\n",
    "modes = 12\n",
    "width = 20\n",
    "\n",
    "batch_size = 1\n",
    "batch_size2 = batch_size\n",
    "\n",
    "epochs = 500\n",
    "learning_rate = 0.0025\n",
    "scheduler_step = 100\n",
    "scheduler_gamma = 0.5\n",
    "\n",
    "print(epochs, learning_rate, scheduler_step, scheduler_gamma)\n",
    "\n",
    "path = 'ns_fourier_2d_rnn_V10000_T20_N'+str(ntrain)+'_ep' + str(epochs) + '_m' + str(modes) + '_w' + str(width)\n",
    "path_model = 'model/'+path\n",
    "path_train_err = 'results/'+path+'train.txt'\n",
    "path_test_err = 'results/'+path+'test.txt'\n",
    "path_image = 'image/'+path\n",
    "\n",
    "runtime = np.zeros(2, )\n",
    "t1 = default_timer()\n",
    "\n",
    "sub = 1\n",
    "S = 64\n",
    "T_in = 10\n",
    "T = 2\n",
    "step = 1\n",
    "\n",
    "################################################################\n",
    "# load data\n",
    "################################################################\n",
    "\n",
    "reader = MatReader(TRAIN_PATH)\n",
    "train_a = reader.read_field('u')[:ntrain,::sub,::sub,:T_in]\n",
    "train_u = reader.read_field('u')[:ntrain,::sub,::sub,T_in:T+T_in]\n",
    "\n",
    "modes = reader.read_field('Modetensorabridged')\n",
    "\n",
    "reader = MatReader(TEST_PATH)\n",
    "test_a = reader.read_field('u')[-ntest:,::sub,::sub,:T_in]\n",
    "test_u = reader.read_field('u')[-ntest:,::sub,::sub,T_in:T+T_in]\n",
    "\n",
    "print(train_u.shape)\n",
    "print(test_u.shape)\n",
    "assert (S == train_u.shape[-2])\n",
    "assert (T == train_u.shape[-1])\n",
    "\n",
    "train_a = train_a.reshape(ntrain,S,S,T_in)\n",
    "test_a = test_a.reshape(ntest,S,S,T_in)\n",
    "\n",
    "# pad the location (x,y)\n",
    "gridx = torch.tensor(np.linspace(0, 1, S), dtype=torch.float)\n",
    "gridx = gridx.reshape(1, S, 1, 1).repeat([1, 1, S, 1])\n",
    "gridy = torch.tensor(np.linspace(0, 1, S), dtype=torch.float)\n",
    "gridy = gridy.reshape(1, 1, S, 1).repeat([1, S, 1, 1])\n",
    "\n",
    "train_a = torch.cat((gridx.repeat([ntrain,1,1,1]), gridy.repeat([ntrain,1,1,1]), train_a), dim=-1)\n",
    "test_a = torch.cat((gridx.repeat([ntest,1,1,1]), gridy.repeat([ntest,1,1,1]), test_a), dim=-1)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(train_a, train_u), batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(test_a, test_u), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "t2 = default_timer()\n",
    "\n",
    "print('preprocessing finished, time used:', t2-t1)\n",
    "device = torch.device('cuda')\n",
    "\n",
    "################################################################\n",
    "# training and evaluation\n",
    "################################################################\n",
    "\n",
    "model = Net2d(modes, width).cuda()\n",
    "# model = torch.load('model/ns_fourier_V100_N1000_ep100_m8_w20')\n",
    "\n",
    "print(model.count_params())\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=scheduler_step, gamma=scheduler_gamma)\n",
    "\n",
    "\n",
    "myloss = LpLoss(size_average=False)\n",
    "gridx = gridx.to(device)\n",
    "gridy = gridy.to(device)\n",
    "\n",
    "for ep in range(epochs):\n",
    "    model.train()\n",
    "    t1 = default_timer()\n",
    "    train_l2_step = 0\n",
    "    train_l2_full = 0\n",
    "    for xx, yy in train_loader:\n",
    "        loss = 0\n",
    "        xx = xx.to(device)\n",
    "        yy = yy.to(device)\n",
    "\n",
    "        for t in range(0, T, step):\n",
    "            y = yy[..., t:t + step]\n",
    "            im = model(xx)\n",
    "            loss += myloss(im.reshape(batch_size, -1), y.reshape(batch_size, -1))\n",
    "\n",
    "            if t == 0:\n",
    "                pred = im\n",
    "            else:\n",
    "                pred = torch.cat((pred, im), -1)\n",
    "\n",
    "            xx = torch.cat((xx[..., step:-2], im,\n",
    "                            gridx.repeat([batch_size, 1, 1, 1]), gridy.repeat([batch_size, 1, 1, 1])), dim=-1)\n",
    "\n",
    "        train_l2_step += loss.item()\n",
    "        l2_full = myloss(pred.reshape(batch_size, -1), yy.reshape(batch_size, -1))\n",
    "        train_l2_full += l2_full.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        # l2_full.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    test_l2_step = 0\n",
    "    test_l2_full = 0\n",
    "    with torch.no_grad():\n",
    "        for xx, yy in test_loader:\n",
    "            loss = 0\n",
    "            xx = xx.to(device)\n",
    "            yy = yy.to(device)\n",
    "\n",
    "            for t in range(0, T, step):\n",
    "                y = yy[..., t:t + step]\n",
    "                im = model(xx)\n",
    "                loss += myloss(im.reshape(batch_size, -1), y.reshape(batch_size, -1))\n",
    "\n",
    "                if t == 0:\n",
    "                    pred = im\n",
    "                else:\n",
    "                    pred = torch.cat((pred, im), -1)\n",
    "\n",
    "                xx = torch.cat((xx[..., step:-2], im,\n",
    "                                gridx.repeat([batch_size, 1, 1, 1]), gridy.repeat([batch_size, 1, 1, 1])), dim=-1)\n",
    "\n",
    "\n",
    "            test_l2_step += loss.item()\n",
    "            test_l2_full += myloss(pred.reshape(batch_size, -1), yy.reshape(batch_size, -1)).item()\n",
    "\n",
    "    t2 = default_timer()\n",
    "    scheduler.step()\n",
    "    print(ep, t2 - t1, train_l2_step / ntrain / (T / step), train_l2_full / ntrain, test_l2_step / ntest / (T / step),\n",
    "          test_l2_full / ntest)\n",
    "    \n",
    "torch.save(model, path_model)\n",
    "\n",
    "\n",
    "pred = torch.zeros(test_u.shape)\n",
    "index = 0\n",
    "test_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(test_a, test_u), batch_size=1, shuffle=False)\n",
    "with torch.no_grad():\n",
    "     for x, y in test_loader:\n",
    "         test_l2 = 0;\n",
    "         x, y = x.cuda(), y.cuda()\n",
    "\n",
    "         out = model(x)\n",
    "         out = y_normalizer.decode(out)\n",
    "         pred[index] = out\n",
    "\n",
    "         test_l2 += myloss(out.view(1, -1), y.view(1, -1)).item()\n",
    "         print(index, test_l2)\n",
    "         index = index + 1\n",
    "\n",
    "scipy.io.savemat('pred/'+path+'.mat', mdict={'pred': pred.cpu().numpy()})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
